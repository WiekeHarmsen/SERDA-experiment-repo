{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-dutch\n",
    "from huggingsound import SpeechRecognitionModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/vol/tensusers2/wharmsen/SERDA-annotations/round1_words_jan/ASTLA_word_correctness_annotations_janneke_2023.09.24_words1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "       141, 142, 143, 144, 145, 146, 147, 148, 149, 150])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(102,151,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/15/2023 09:51:15 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-dutch\")\n",
    "\n",
    "filePath = '/vol/tensusers2/wharmsen/SERDA/round1/audio/words/segments/2RRDV-words_1_xxx-20230113140713310.wav'\n",
    "audio_paths = [filePath.replace('xxx', str(wordID)) for wordID in np.arange(102,150,1)]\n",
    "\n",
    "# audio_paths = [\"/path/to/file.mp3\", \"/path/to/another_file.wav\"]\n",
    "\n",
    "adagt.two_way_alignment(promptPart, asrTransPart)\n",
    "transcriptions = model.transcribe(audio_paths[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'transcription': 'vier',\n",
       "  'start_timestamps': [1240, 1320, 1440, 1500],\n",
       "  'end_timestamps': [1260, 1340, 1460, 1520],\n",
       "  'probabilities': [0.9999325275421143,\n",
       "   0.9999547004699707,\n",
       "   0.9999018907546997,\n",
       "   0.9999938011169434]},\n",
       " {'transcription': 'eint',\n",
       "  'start_timestamps': [820, 960, 1020, 1160],\n",
       "  'end_timestamps': [840, 980, 1040, 1180],\n",
       "  'probabilities': [0.5914125442504883,\n",
       "   0.5461336970329285,\n",
       "   0.9999867677688599,\n",
       "   0.6887324452400208]},\n",
       " {'transcription': 'em boor',\n",
       "  'start_timestamps': [1400, 1500, 1540, 1580, 1660, 1820, 1880],\n",
       "  'end_timestamps': [1420, 1520, 1560, 1600, 1680, 1840, 1900],\n",
       "  'probabilities': [0.4848102629184723,\n",
       "   0.6564676761627197,\n",
       "   0.9158182740211487,\n",
       "   0.9935368895530701,\n",
       "   0.9999760389328003,\n",
       "   0.6372667551040649,\n",
       "   0.999991774559021]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.] 16000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "LANG_ID = \"nl\"\n",
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-dutch\"\n",
    "SAMPLES = 10\n",
    "\n",
    "audio_file = '/vol/tensusers2/wharmsen/SERDA/round1/audio/words/segments/2RRDV-words_1_102-20230113140713310.wav'\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "audio, sr = librosa.load(audio_file, sr=16_000)\n",
    "\n",
    "print(audio,sr)\n",
    "inputs = processor(audio, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: vier\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Reference:\", test_dataset[i][\"sentence\"])\n",
    "    print(\"Prediction:\", predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv-wav2vec2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
