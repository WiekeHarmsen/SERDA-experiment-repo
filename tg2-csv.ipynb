{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to read the manual annotations from the TextGrid (on chunk and attempts level) and convert them to a csv where each row represents a chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tgt # https://textgridtools.readthedocs.io/en/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tg_file = '/vol/tensusers5/wharmsen/astla-data/dart-preposttest/specom-data/annotations_6sep/stephanie_v1/5fcccbb2-d4e2-4e75-ada9-be011f69c55c_checked.TextGrid'\n",
    "# audio_filename = os.path.basename(tg_file).replace('_checked.TextGrid', '')\n",
    "\n",
    "tg_file = '/vol/tensusers2/wharmsen/SERDA-annotations/round1_stories_all_marjul/textgrid/set1_jul/ZPGND-story_3-20230116114853113_checked.TextGrid'\n",
    "filename = os.path.basename(tg_file).replace('_checked.TextGrid', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier_name</th>\n",
       "      <th>tier_type</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>description</td>\n",
       "      <td>IntervalTier</td>\n",
       "      <td>121.4052373071388</td>\n",
       "      <td>121.69748687465527</td>\n",
       "      <td>cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>description</td>\n",
       "      <td>IntervalTier</td>\n",
       "      <td>122.16222360626742</td>\n",
       "      <td>122.3856713692632</td>\n",
       "      <td>cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>description</td>\n",
       "      <td>IntervalTier</td>\n",
       "      <td>122.3856713692632</td>\n",
       "      <td>122.83712705368328</td>\n",
       "      <td>cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>description</td>\n",
       "      <td>IntervalTier</td>\n",
       "      <td>123.20193972796213</td>\n",
       "      <td>123.73304092008289</td>\n",
       "      <td>del</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>description</td>\n",
       "      <td>IntervalTier</td>\n",
       "      <td>123.7740823452826</td>\n",
       "      <td>124.26201928932356</td>\n",
       "      <td>cor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tier_name     tier_type          start_time            end_time text\n",
       "1071  description  IntervalTier   121.4052373071388  121.69748687465527  cor\n",
       "1072  description  IntervalTier  122.16222360626742   122.3856713692632  cor\n",
       "1073  description  IntervalTier   122.3856713692632  122.83712705368328  cor\n",
       "1074  description  IntervalTier  123.20193972796213  123.73304092008289  del\n",
       "1075  description  IntervalTier   123.7740823452826  124.26201928932356  cor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function reads a .tg file and saves it as a dataframe where each row represents one interval.\n",
    "The columns are the following five properties: tier_name, tier_type, start_time, end_time, text\n",
    "\"\"\"\n",
    "def read_textgrid_to_dataframe(tg_file, audio_filename):\n",
    "    \n",
    "    # Read TextGrid file\n",
    "    tg = tgt.io.read_textgrid(tg_file, encoding='utf-8', include_empty_intervals=False)\n",
    "\n",
    "    # Convert TextGrid file to Formatted Table (= df with on each row one interval)\n",
    "    table = tgt.io.export_to_table(tg, separator=', ')\n",
    "    formatted_table = [x.split(', ') for x in table.split('\\n')]\n",
    "\n",
    "    tg_df = pd.DataFrame(formatted_table[1:], columns = formatted_table[0])\n",
    "\n",
    "    # with open(textgrids_as_table_dir + audio_filename + '.csv', 'w') as f:\n",
    "    #     f.write(table)\n",
    "\n",
    "    return tg_df\n",
    "\n",
    "tg_df = read_textgrid_to_dataframe(tg_file, filename)\n",
    "tg_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_typos_annotations(tg_df):\n",
    "    prompts = [x.split(' ')[0] for x in tg_df[tg_df['tier_name'] == 'prompts'].loc[:,'text']]\n",
    "    chunks = list(tg_df[tg_df['tier_name'] == 'chunks'].loc[:,'text'])\n",
    "\n",
    "    difference = list({p for p in prompts} - {c for c in chunks})\n",
    "\n",
    "    if(len(difference) > 0):\n",
    "        print(difference)\n",
    "\n",
    "def print_comments(tg_df):\n",
    "    try: \n",
    "        print(tg_df[tg_df['tier_name'] == 'comments']['text'])\n",
    "    except:\n",
    "        print( 'no comments')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant info from tier 1: prompts in chunks_df\n",
    "\n",
    "def initialize_chunks_df(tg_df, audio_filename):\n",
    "    chunks_df = tg_df[tg_df['tier_name'] == 'prompts']\n",
    "    chunks_df.loc[:,'name'] = [audio_filename + '_' + prompt.split(' ')[0] for prompt in list(chunks_df['text'])]\n",
    "    # chunks_df = chunks_df.loc[:, ['name', 'text']]\n",
    "    chunks_df = chunks_df.drop(['tier_name', 'tier_type'], axis=1)\n",
    "    chunks_df = chunks_df.set_axis([audio_filename + '_' + prompt.split(' ')[0] for prompt in chunks_df['text']], axis='index')\n",
    "\n",
    "    return chunks_df\n",
    "\n",
    "# chunks_df = initialize_chunks_df(tg_df, audio_filename)\n",
    "# chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information from tier 2: chunks\n",
    "\n",
    "def expand_chunks_df_with_chunks(tg_df, chunks_df, audio_filename):\n",
    "    chunks_df['chunks'] = ''\n",
    "    chunks_df['start_time'] = ''\n",
    "    chunks_df['end_time'] = ''\n",
    "\n",
    "    tg_df_chunks = tg_df[tg_df['tier_name'] == 'chunks']\n",
    "\n",
    "    for idx, row in tg_df_chunks.iterrows():\n",
    "        word = row['text']\n",
    "        chunks_df.loc[audio_filename +'_'+ word, 'chunks'] = row['text']\n",
    "        chunks_df.loc[audio_filename +'_'+ word, 'start_time'] = row['start_time']\n",
    "        chunks_df.loc[audio_filename +'_'+ word, 'end_time'] = row['end_time']  \n",
    "\n",
    "    # chunks_df['chunks'] = list(tg_df[tg_df['tier_name'] == 'chunks'].loc[:,'text'])\n",
    "    # chunks_df['start_time'] = list(tg_df[tg_df['tier_name'] == 'chunks'].loc[:,'start_time'])\n",
    "    # chunks_df['end_time'] = list(tg_df[tg_df['tier_name'] == 'chunks'].loc[:,'end_time'])\n",
    "\n",
    "    return chunks_df\n",
    "\n",
    "# chunks_df = expand_chunks_df_with_chunks(tg_df, chunks_df, audio_filename)\n",
    "# chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information from the other tiers, that have attempt boundaries instead of chunk boundaries.\n",
    "# Match 0, 1, 2 or more attempts with one chunk.\n",
    "\n",
    "def add_attempts_info_to_chunks_df(tg_df, chunks_df):\n",
    "\n",
    "    attempts_df = tg_df[tg_df['tier_name'].isin(['attempts', 'attemptsPhones', 'correct', 'description'])]\n",
    "\n",
    "    resulting_matrix = []\n",
    "\n",
    "    for idx, chunkInfo in chunks_df.iterrows():\n",
    "        startTimeChunk = chunkInfo['start_time']\n",
    "        endTimeChunk = chunkInfo['end_time']\n",
    "\n",
    "        resulting_info = [startTimeChunk, endTimeChunk]\n",
    "\n",
    "        for annotationType in ['attempts', 'attemptsPhones', 'correct', 'description']:\n",
    "\n",
    "            # Get first and last attempt on certain chunk\n",
    "            try:\n",
    "                startAttemptIdx = attempts_df[(attempts_df['start_time'] == startTimeChunk) & (attempts_df['tier_name'] == annotationType)].index[0]\n",
    "                endAttemptIdx = attempts_df[(attempts_df['end_time'] == endTimeChunk) & (attempts_df['tier_name'] == annotationType)].index[0]\n",
    "\n",
    "                # Combine all attempts for one chunk\n",
    "                attempts_to_chunks_list = []\n",
    "                for idx in np.arange(startAttemptIdx, endAttemptIdx+1, 1):\n",
    "                    attempts_to_chunks_list.append(attempts_df.loc[idx, 'text'])\n",
    "\n",
    "                resulting_info.append(\"-\".join(attempts_to_chunks_list))\n",
    "            \n",
    "            except:\n",
    "                # prompt is not read, add default annotation\n",
    "                resulting_info.append(\"\")\n",
    "            \n",
    "\n",
    "        resulting_matrix.append(resulting_info)\n",
    "\n",
    "    attempts_info_df = pd.DataFrame(resulting_matrix, columns = ['attemptsStart', 'attemptsEnd', 'graphTrans', 'phonTrans', 'assessment', 'assessmentDescription'])\n",
    "\n",
    "    # Attempts_info_df and chunks_df should be matched on startTime\n",
    "    attempts_info_df_time_index = attempts_info_df.rename(columns={\"attemptsStart\": \"start_time\"}).set_index('start_time')\n",
    "    chunks_df_time_index = chunks_df.set_index('start_time')\n",
    "\n",
    "    return chunks_df_time_index.join(attempts_info_df_time_index).reset_index().set_index('name')\n",
    "\n",
    "# attempts_info_df = add_attempts_info_to_chunks_df(tg_df, chunks_df)\n",
    "# attempts_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# For each TextGrid with manual annotations\n",
    "for tg_file in textgrid_files:\n",
    "\n",
    "    # Get audio file name\n",
    "    tg_audio_name = os.path.basename(tg_file).replace('_checked.TextGrid', '.mp3')\n",
    "    audio_filename = os.path.basename(tg_file).replace('_checked.TextGrid', '')\n",
    "\n",
    "    try:\n",
    "        tg_df = read_textgrid_to_dataframe(tg_file, audio_filename)\n",
    "    except: \n",
    "        print('Corrupt TextGrid file')\n",
    "\n",
    "    print(audio_filename)\n",
    "    print_typos_annotations(tg_df)\n",
    "    print_comments(tg_df)\n",
    "\n",
    "    chunks_df = initialize_chunks_df(tg_df, audio_filename)\n",
    "    chunks_df = expand_chunks_df_with_chunks(tg_df, chunks_df, audio_filename)\n",
    "    chunks_df = add_attempts_info_to_chunks_df(tg_df, chunks_df)\n",
    "\n",
    "    if len(chunks_df) == 24:\n",
    "        chunks_df.to_csv(chunks_attempts_matched_dir + audio_filename + '.csv')\n",
    "    else: \n",
    "        chunks_df.to_csv(chunks_attempts_not_matched_dir + audio_filename + '.csv')\n",
    "    print('\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv-wav2vec2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
